{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import neighbors\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import ElasticNet, Ridge, Lasso, LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOTTING CONFIGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 20\n",
    "BIGGER_SIZE = 24\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_VERSION = 'exp_v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGURATIONS = './configurations/'\n",
    "config_file_name = EXPERIMENT_VERSION + '.json'\n",
    "\n",
    "config_file_name_path = os.path.join(CONFIGURATIONS + config_file_name)\n",
    "\n",
    "with open(config_file_name_path, 'r') as f:\n",
    "    configuration = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'date': 'transactiondate', 'target': 'logerror', 'kfold': 10},\n",
       " 'features': {'heatingorsystemtypeid': {'missing': 'Mean',\n",
       "   'category_encoding': None,\n",
       "   'feature_standarization': 'Standard'},\n",
       "  'regionidcity': {'missing': 'Mean',\n",
       "   'category_encoding': None,\n",
       "   'feature_standarization': 'MinMax'},\n",
       "  'yearbuilt': {'missing': 'Mean',\n",
       "   'category_encoding': None,\n",
       "   'feature_standarization': 'MinMax'},\n",
       "  'lotsizesquarefeet': {'missing': 'Mean',\n",
       "   'category_encoding': None,\n",
       "   'feature_standarization': 'Standard'},\n",
       "  'taxvaluedollarcnt': {'missing': 'Mean',\n",
       "   'category_encoding': None,\n",
       "   'feature_standarization': 'MinMax'},\n",
       "  'rawcensustractandblock': {'missing': 'Mean',\n",
       "   'category_encoding': None,\n",
       "   'feature_standarization': 'Standard'},\n",
       "  'buildingqualitytypeid': {'missing': 'Mean',\n",
       "   'category_encoding': None,\n",
       "   'feature_standarization': 'Standard'}},\n",
       " 'feature_selection': {'operation': 'RFE', 'num_feats': 7},\n",
       " 'features_to_analyze': ['transactiondate', 'logerror']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "TRAIN_DATA = os.path.join(DATA_DIR, \"base_data/train.csv\")\n",
    "date_feature = configuration['metadata']['date']\n",
    "train_df = pd.read_csv(TRAIN_DATA, parse_dates= [date_feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_DIR = './results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heatingorsystemtypeid</th>\n",
       "      <th>buildingqualitytypeid</th>\n",
       "      <th>propertyzoningdesc</th>\n",
       "      <th>unitcnt</th>\n",
       "      <th>lotsizesquarefeet</th>\n",
       "      <th>finishedsquarefeet12</th>\n",
       "      <th>regionidcity</th>\n",
       "      <th>calculatedbathnbr</th>\n",
       "      <th>fullbathcnt</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>...</th>\n",
       "      <th>fips</th>\n",
       "      <th>roomcnt</th>\n",
       "      <th>regionidcounty</th>\n",
       "      <th>rawcensustractandblock</th>\n",
       "      <th>propertylandusetypeid</th>\n",
       "      <th>propertycountylandusecode</th>\n",
       "      <th>longitude</th>\n",
       "      <th>transactiondate</th>\n",
       "      <th>logerror</th>\n",
       "      <th>parcelid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4506.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>53571.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6059.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1286.0</td>\n",
       "      <td>6.059063e+07</td>\n",
       "      <td>261.0</td>\n",
       "      <td>122</td>\n",
       "      <td>-117869207.0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.025595</td>\n",
       "      <td>14297519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12647.0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>13091.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6111.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2061.0</td>\n",
       "      <td>6.111001e+07</td>\n",
       "      <td>261.0</td>\n",
       "      <td>1110</td>\n",
       "      <td>-119281531.0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.055619</td>\n",
       "      <td>17052889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8432.0</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>21412.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6059.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1286.0</td>\n",
       "      <td>6.059022e+07</td>\n",
       "      <td>261.0</td>\n",
       "      <td>122</td>\n",
       "      <td>-117823170.0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>14186244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>LCR110000*</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13038.0</td>\n",
       "      <td>2376.0</td>\n",
       "      <td>396551.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3101.0</td>\n",
       "      <td>6.037300e+07</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0101</td>\n",
       "      <td>-118240722.0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>-0.103410</td>\n",
       "      <td>12177905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>LAR3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>278581.0</td>\n",
       "      <td>1312.0</td>\n",
       "      <td>12447.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3101.0</td>\n",
       "      <td>6.037124e+07</td>\n",
       "      <td>266.0</td>\n",
       "      <td>010C</td>\n",
       "      <td>-118414640.0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.006940</td>\n",
       "      <td>10887214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>903.0</td>\n",
       "      <td>1492.0</td>\n",
       "      <td>51239.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6111.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2061.0</td>\n",
       "      <td>6.111005e+07</td>\n",
       "      <td>266.0</td>\n",
       "      <td>1129</td>\n",
       "      <td>-118993991.0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>-0.020526</td>\n",
       "      <td>17143294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>PSR2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>2962.0</td>\n",
       "      <td>47019.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3101.0</td>\n",
       "      <td>6.037461e+07</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0101</td>\n",
       "      <td>-118179824.0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>-0.001011</td>\n",
       "      <td>12095076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>GLR4YY</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4214.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>45457.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3101.0</td>\n",
       "      <td>6.037302e+07</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0100</td>\n",
       "      <td>-118239357.0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.101723</td>\n",
       "      <td>12069064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>WHRE20000*</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20028.0</td>\n",
       "      <td>3039.0</td>\n",
       "      <td>14634.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3101.0</td>\n",
       "      <td>6.037500e+07</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0100</td>\n",
       "      <td>-118006914.0</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>-0.040966</td>\n",
       "      <td>12790562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>LAR3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54048.0</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>12447.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3101.0</td>\n",
       "      <td>6.037275e+07</td>\n",
       "      <td>266.0</td>\n",
       "      <td>010C</td>\n",
       "      <td>-118416000.0</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>-0.036763</td>\n",
       "      <td>11542646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   heatingorsystemtypeid  buildingqualitytypeid propertyzoningdesc  unitcnt  \\\n",
       "0                    NaN                    NaN                NaN      NaN   \n",
       "1                    NaN                    NaN                NaN      NaN   \n",
       "2                    NaN                    NaN                NaN      NaN   \n",
       "3                    2.0                    8.0         LCR110000*      1.0   \n",
       "4                    2.0                    8.0               LAR3      1.0   \n",
       "5                    NaN                    NaN                NaN      NaN   \n",
       "6                    2.0                    9.0               PSR2      1.0   \n",
       "7                    NaN                    5.0             GLR4YY      1.0   \n",
       "8                    2.0                    9.0         WHRE20000*      1.0   \n",
       "9                    2.0                    8.0               LAR3      1.0   \n",
       "\n",
       "   lotsizesquarefeet  finishedsquarefeet12  regionidcity  calculatedbathnbr  \\\n",
       "0             4506.0                3100.0       53571.0                3.5   \n",
       "1            12647.0                1465.0       13091.0                1.0   \n",
       "2             8432.0                1243.0       21412.0                2.0   \n",
       "3            13038.0                2376.0      396551.0                3.0   \n",
       "4           278581.0                1312.0       12447.0                3.0   \n",
       "5              903.0                1492.0       51239.0                2.0   \n",
       "6            63000.0                2962.0       47019.0                3.0   \n",
       "7             4214.0                 738.0       45457.0                1.0   \n",
       "8            20028.0                3039.0       14634.0                3.0   \n",
       "9            54048.0                1290.0       12447.0                3.0   \n",
       "\n",
       "   fullbathcnt  yearbuilt  ...    fips  roomcnt  regionidcounty  \\\n",
       "0          3.0     1998.0  ...  6059.0      0.0          1286.0   \n",
       "1          1.0     1967.0  ...  6111.0      5.0          2061.0   \n",
       "2          2.0     1962.0  ...  6059.0      6.0          1286.0   \n",
       "3          3.0     1970.0  ...  6037.0      0.0          3101.0   \n",
       "4          3.0     1964.0  ...  6037.0      0.0          3101.0   \n",
       "5          2.0     1982.0  ...  6111.0      6.0          2061.0   \n",
       "6          3.0     1950.0  ...  6037.0      0.0          3101.0   \n",
       "7          1.0     1922.0  ...  6037.0      0.0          3101.0   \n",
       "8          3.0     1970.0  ...  6037.0      0.0          3101.0   \n",
       "9          3.0     1980.0  ...  6037.0      0.0          3101.0   \n",
       "\n",
       "   rawcensustractandblock  propertylandusetypeid  propertycountylandusecode  \\\n",
       "0            6.059063e+07                  261.0                        122   \n",
       "1            6.111001e+07                  261.0                       1110   \n",
       "2            6.059022e+07                  261.0                        122   \n",
       "3            6.037300e+07                  261.0                       0101   \n",
       "4            6.037124e+07                  266.0                       010C   \n",
       "5            6.111005e+07                  266.0                       1129   \n",
       "6            6.037461e+07                  261.0                       0101   \n",
       "7            6.037302e+07                  261.0                       0100   \n",
       "8            6.037500e+07                  261.0                       0100   \n",
       "9            6.037275e+07                  266.0                       010C   \n",
       "\n",
       "     longitude  transactiondate  logerror  parcelid  \n",
       "0 -117869207.0       2017-01-01  0.025595  14297519  \n",
       "1 -119281531.0       2017-01-01  0.055619  17052889  \n",
       "2 -117823170.0       2017-01-01  0.005383  14186244  \n",
       "3 -118240722.0       2017-01-01 -0.103410  12177905  \n",
       "4 -118414640.0       2017-01-01  0.006940  10887214  \n",
       "5 -118993991.0       2017-01-01 -0.020526  17143294  \n",
       "6 -118179824.0       2017-01-01 -0.001011  12095076  \n",
       "7 -118239357.0       2017-01-01  0.101723  12069064  \n",
       "8 -118006914.0       2017-01-02 -0.040966  12790562  \n",
       "9 -118416000.0       2017-01-02 -0.036763  11542646  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imputation_value(train, i, operation):\n",
    "    \"\"\" Find the imputing value on behalf of the operation\n",
    "    \"\"\"\n",
    "    if operation == 'Mean':\n",
    "        return train[i].mean()\n",
    "    if operation == 'Mode':\n",
    "        return train[i].mode()[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(train, val):\n",
    "    \"\"\" Fills the column with the imputing value\n",
    "    \"\"\"\n",
    "    \n",
    "    target = configuration['metadata']['target']\n",
    "    list_of_features = configuration['features']   \n",
    "    \n",
    "    for feature, operations in list_of_features.items():\n",
    "        operation = operations['missing']\n",
    "        imputing_value = get_imputation_value(train, feature, operation)\n",
    "        train[feature].fillna(imputing_value, inplace = True)\n",
    "        val[feature].fillna(imputing_value, inplace = True)\n",
    "        \n",
    "    return train, val  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_objects = dict()\n",
    "def data_standarization_train(series, feature, operation):\n",
    "\n",
    "    df_train = pd.DataFrame([series]).T\n",
    "    df_train.columns = [feature]\n",
    "    \n",
    "    \n",
    "    scaler_object = get_scaler_object(df_train, operation)\n",
    "    \n",
    "    scaler_objects.update({str(series.name): scaler_object})\n",
    "    \n",
    "    df_train = scaler_object.transform(df_train)\n",
    "    df_train = pd.DataFrame(df_train, columns= [feature])\n",
    "    return df_train[feature].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_standarization_val(series, feature, operation):\n",
    "    \n",
    "    df_val = pd.DataFrame([series]).T\n",
    "    df_val.columns = [feature]\n",
    "    scaler_object = scaler_objects[str(series.name)]\n",
    "    \n",
    "    df_val = scaler_object.fit_transform(df_val)\n",
    "    df_val = pd.DataFrame(df_val, columns= [feature])\n",
    "    return df_val[feature].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaler_object(df, operation):\n",
    "    \n",
    "    if operation == 'MinMax':\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "    if operation == 'Standard':\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "    if operation == 'BoxCox':\n",
    "        scaler = preprocessing.PowerTransformer()    \n",
    "    if operation == 'QuantileTransformer':\n",
    "        scaler = preprocessing.QuantileTransformer() \n",
    "    \n",
    "    return scaler.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_transform(train, val, feature, operation):\n",
    "    \n",
    "    df_train = pd.DataFrame(train[feature])\n",
    "    df_train.columns = [feature]\n",
    "    \n",
    "    df_val = pd.DataFrame(val[feature])\n",
    "    df_val.columns = [feature]\n",
    "    \n",
    "    scaler_object = get_scaler_object(df_train, operation)\n",
    "    \n",
    "    df_train = scaler_object.transform(df_train)\n",
    "    df_train = pd.DataFrame(df_train, columns= [feature])\n",
    "    \n",
    "    df_val = scaler_object.transform(df_val)\n",
    "    df_val = pd.DataFrame(df_val, columns= [feature])\n",
    "    \n",
    "    return df_train[feature].values, df_val[feature].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_by_group_feature(train, val,feature, operation, groupby_feature):\n",
    "    train[feature] = train.groupby(groupby_feature)[feature].transform(lambda x : data_standarization_train(x, feature, operation))\n",
    "    val[feature] =  val.groupby(groupby_feature)[feature].transform(lambda x : data_standarization_val(x, feature, operation))\n",
    "    return train[feature], val[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_standarization(train, val):\n",
    "    \n",
    "    target = configuration['metadata']['target']\n",
    "    list_of_features = configuration['features']     \n",
    "    \n",
    "    for feature, operations in list_of_features.items():\n",
    "        \n",
    "        operation = operations['feature_standarization']\n",
    "        if not operation:\n",
    "            continue\n",
    "        train[feature], val[feature] = numerical_transform(train, val, feature, operation)\n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(train, val, feature, operation):\n",
    "    \n",
    "    \n",
    "    df_train = pd.DataFrame(train[feature])\n",
    "    df_train.columns = [feature]\n",
    "    \n",
    "    df_val = pd.DataFrame(val[feature])\n",
    "    df_val.columns = [feature]\n",
    "    \n",
    "    categorical_encoder = get_categorical_encoder(df_train, type)\n",
    "    \n",
    "    df_train = categorical_encoder.transform(df_train)\n",
    "    df_train = pd.DataFrame(df_train, columns= [feature])\n",
    "    \n",
    "    try:\n",
    "        df_val = categorical_encoder.transform(df_val)\n",
    "        df_val = pd.DataFrame(df_val, columns= [feature])\n",
    "    except Exception as e: \n",
    "        print('e', e)\n",
    "     \n",
    "    return df_train[feature].values, df_val[feature].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_encoder(df_train, operation ):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    return le.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_feature_standarization(train, val):\n",
    "    \n",
    "    target = configuration['metadata']['target']\n",
    "    list_of_features = configuration['features']   \n",
    "\n",
    "    for feature, operations in list_of_features.items():\n",
    "        operation = operations['category_encoding']\n",
    "        if not operation:\n",
    "            continue\n",
    "        train[feature], val[feature] = transform(train, val, feature, operation)\n",
    "        \n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(train, val):\n",
    "    target = configuration['metadata']['target']\n",
    "    operation = configuration['feature_selection']['operation']\n",
    "    num_feats = configuration['feature_selection']['num_feats']\n",
    "    drop_features = [target , configuration['metadata']['date']]\n",
    "    \n",
    "    X = train.drop(drop_features, axis = 1)\n",
    "    y = train[target]\n",
    "    \n",
    "    print(\"Number of features Inputed\",  len(X.columns.to_list()))\n",
    "    print(\"Features-\", X.columns)\n",
    "    \n",
    "    \n",
    "    if operation == 'corr':\n",
    "        important_features, _ = select_from_corr(X, y, num_feats)\n",
    "    if operation == 'k_best':\n",
    "        important_features, _ = select_kBest(X,y, num_feats)\n",
    "    \n",
    "    if operation == 'RFE':\n",
    "        important_features, _ = select_from_rfe(X,y, num_feats)\n",
    "        \n",
    "    if operation == 'select_from_model':\n",
    "        important_features, _ = select_from_model(X,y, num_feats)    \n",
    "    \n",
    "    \n",
    "    print('number of feature selected', len(important_features))\n",
    "    display('feature_selected',important_features )\n",
    "    important_features = important_features + drop_features \n",
    "    \n",
    "\n",
    "    return train[important_features], val[important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_from_corr(X, y, num_feats):\n",
    "    cor_list = []\n",
    "    feature_name = X.columns.tolist()\n",
    "    # calculate the correlation with y for each feature\n",
    "    for i in X.columns.tolist():\n",
    "        cor = np.corrcoef(X[i], y)[0, 1]\n",
    "        cor_list.append(cor)\n",
    "    # replace NaN with 0\n",
    "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "    # feature name\n",
    "    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n",
    "    # feature selection? 0 for not select, 1 for select\n",
    "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
    "    return cor_feature, cor_support\n",
    "\n",
    "def select_kBest(X,y, num_feats):\n",
    "    f_regression_selector = SelectKBest(f_regression, k=num_feats)\n",
    "    f_regression_selector.fit(X, y)\n",
    "    f_regression_selector_support = f_regression_selector.get_support()\n",
    "    f_regression_selector_feature = X.loc[:,f_regression_selector_support].columns.tolist()\n",
    "    return f_regression_selector_feature, f_regression_selector_support\n",
    "\n",
    "\n",
    "def select_from_rfe(X,y, num_feats):\n",
    "    rfe_selector = RFE(estimator= RandomForestRegressor(), n_features_to_select=num_feats, step=10, verbose=5)\n",
    "    rfe_selector.fit(X, y)\n",
    "    rfe_support = rfe_selector.get_support()\n",
    "    rfe_feature = X.loc[:,rfe_support].columns.tolist()\n",
    "    return rfe_feature, rfe_support\n",
    "   \n",
    "\n",
    "def select_from_model(X,y, model, num_feats):\n",
    "    embeded_lr_selector = SelectFromModel(model, max_features=num_feats)\n",
    "    embeded_lr_selector.fit(X, y)\n",
    "\n",
    "    embeded_lr_support = embeded_lr_selector.get_support()\n",
    "    embeded_lr_feature = X.loc[:,embeded_lr_support].columns.tolist()\n",
    "    return embeded_lr_feature, embeded_lr_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_feature_extraction(train_kf, val_kf):\n",
    "    date_feature = configuration['metadata']['date']\n",
    "    \n",
    "    train_kf['day'] = train_kf[date_feature].dt.day\n",
    "    train_kf['week'] = train_kf[date_feature].dt.week\n",
    "    \n",
    "    val_kf['day'] = val_kf[date_feature].dt.day\n",
    "    val_kf['week'] = val_kf[date_feature].dt.week\n",
    "    \n",
    "\n",
    "    return train_kf, val_kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features():\n",
    "    features = list(configuration['features'].keys() )\n",
    "    features.append(configuration['metadata']['date'])\n",
    "    features.append(configuration['metadata']['target'])\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing_target_values(train_kf, val_kf):\n",
    "    target = configuration['metadata']['target']\n",
    "    train_kf = train_kf.loc[~train_kf[target].isnull()]\n",
    "    val_kf = val_kf.loc[~val_kf[target].isnull()]\n",
    "    return train_kf, val_kf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold_indexs(df):\n",
    "    per_fold_indexes = dict()\n",
    "    n_splits = configuration['metadata']['kfold']\n",
    "    \n",
    "    kfold = model_selection.KFold(n_splits = n_splits, shuffle=True)\n",
    "    kfold.split(train_df)\n",
    "    for fold, (train_index, val_index) in enumerate(kfold.split(df)):\n",
    "        per_fold_indexes.update({fold: (train_index, val_index )})\n",
    "        \n",
    "    return per_fold_indexes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(df, per_fold_indexes):  \n",
    "    \n",
    "    \"\"\" Heart of the pipleline , here each module is independent of the other so they can be asily \n",
    "        added or remove from the pipeline\n",
    "    \"\"\"\n",
    "    \n",
    "    for fold in range(0,n_splits) :\n",
    "        train_index = per_fold_indexes[fold][0]\n",
    "        val_index = per_fold_indexes[fold][1]\n",
    "        \n",
    "        \n",
    "        train_kf = df.loc[train_index]\n",
    "        val_kf =  df.loc[val_index]\n",
    "        \n",
    "        select_columns = list(configuration['features'].keys() )\n",
    "        select_columns.append(configuration['metadata']['date'])\n",
    "        \n",
    "        features = select_features()\n",
    "        train_kf = train_kf[features]\n",
    "        val_kf = val_kf[features]\n",
    "        \n",
    "        train_kf, val_kf = drop_missing_target_values(train_kf, val_kf)                       \n",
    "        train_kf, val_kf = fill_missing_values(train_kf, val_kf)\n",
    "        train_kf, val_kf = time_feature_extraction(train_kf, val_kf)\n",
    "        train_kf, val_kf = category_feature_standarization(train_kf, val_kf)\n",
    "        train_kf, val_kf = feature_standarization(train_kf, val_kf)\n",
    "        train_kf, val_kf = feature_selection(train_kf, val_kf)        \n",
    "        preprocess_data.update({fold: [train_kf, val_kf]})\n",
    "        \n",
    "    return preprocess_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = {\n",
    "    'Linear': LinearRegression(),\n",
    "    'Random': RandomForestRegressor(),\n",
    "    'Lasso': Lasso(),\n",
    "    'Elastic': ElasticNet()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model():\n",
    "    for name, regressor in regressors.items():\n",
    "        n_splits = configuration['metadata']['kfold']\n",
    "        for fold in range(0,4) :\n",
    "\n",
    "            train , val = preprocess_data[fold][0].copy(), preprocess_data[fold][1].copy()\n",
    "                 \n",
    "            target = configuration['metadata']['target']\n",
    "            drop = [configuration['metadata']['date'] , target]\n",
    "            \n",
    "            xtr, xts = train.drop(drop, axis=1), val.drop(drop, axis=1)\n",
    "            ytr, yts = train[target], val[target]\n",
    "\n",
    "            regressor.fit(xtr, ytr)\n",
    "            p = regressor.predict(xts)\n",
    "            \n",
    "            prediction_alias = EXPERIMENT_VERSION + \"_\" + name + \"_\" + str(fold )\n",
    "            val_copy = val.copy()         \n",
    "            val_copy[prediction_alias] = p\n",
    "            \n",
    "            name_of_file = RESULT_DIR + '/' + prediction_alias + '.csv'\n",
    "            val_copy.to_csv(name_of_file, index = False)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajatjain/.pyenv/versions/3.6.6/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "per_fold_indexs = get_fold_indexs(train_df)\n",
    "preprocess_data = data_preprocess(train_df, per_fold_indexes)\n",
    "evaluate_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
